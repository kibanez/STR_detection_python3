"""
Created on 11/12/2019

@author: kristina ibanez-garikano
Following EH philosophy we want to merge the repeat-size in each locus across all cohort
"""

import copy
import logging
import optparse
import os
import re
import sys
import vcf
from configparser import ConfigParser
from operator import itemgetter
from os import path as osp


localModulesBase = osp.dirname(osp.realpath(__file__))

modulesRelDirs = ["../modules/"]

for moduleRelDir in modulesRelDirs:
    sys.path.insert(0, osp.join(localModulesBase, moduleRelDir))


class OptionParser(optparse.OptionParser):
    def check_required(self, opt):

        option = self.get_option(opt)

        atrib = getattr(self.values, option.dest)

        if atrib is None:
            return False
        else:
            return True


def print_tables(hash_table, f_output):
    """
    Function that prints two tsv files: one containing all the EH VCF, already enriched somehow
    and the other table, containing only the STR loci that are spotted by having more repetitions that theoretically
    and in practice have been seen

    :param hash_table: it contains the frequencies for each locus
    :param f_output: file in where the function will write the info in hash_table
    :return:
    """

    l_fields = ['chr', 'repeat-size', 'gene', 'repeat_motif',
                'num_samples', 'AF', 'list_samples']

    l_chr = set([item[0] for item in hash_table.keys()])

    chr_specials = []
    if 'X' in l_chr:
        l_chr.remove('X')
        chr_specials.append('X')
    elif 'Y' in l_chr:
        l_chr.remove('Y')
        chr_specials.append('Y')

    l_chr = sorted(l_chr)
    l_chr = [str(i) for i in l_chr]

    for i in chr_specials:
        l_chr.append(i)

    fo = open(f_output, 'w')
    fo.write('\t'.join(l_fields) + '\n')
    for key in sorted(sorted(hash_table.keys(), key=itemgetter(1)), key=lambda x: l_chr.index(x[0])):
        fo.write('\t'.join(map(lambda field: hash_table[key].get(field, '.'), l_fields)) + '\n')
    fo.close()


def merging_vcf(l_vcf, path_vcf, logger):
    """
    Function that receives a list of individual VCF files to merge them all

    The main objective here is to extract the GT frequencies for each STR loci (being trinucleotide regions)
    It returns a VCF file containing the AF for each STR detected in the whole cohort
    chr   pos ref alt frequency

    :param l_vcf: list of VCF files generated by EH
    :param path_vcf: folder in where l_vcf are located
    :param logger:
    :return:
    """

    hash_table = {}

    total_samples = len(l_vcf)

    for vcf_input in l_vcf:

        name_vcf = vcf_input

        vcf_input = os.path.join(path_vcf, vcf_input)

        if not os.path.isfile(vcf_input):
            raise IOError("The VCF file does not exist %s " % vcf_input)

        logger.info("Analysing the STR regions within %s" % vcf_input)

        # Sometimes the VCF generated by EH is empty. We need to check whether the VCF is empty or not
        if os.path.getsize(vcf_input) == 0:
            print(vcf_input + '\n')
            continue

        vcf_reader = vcf.Reader(filename=vcf_input)

        for i, r in enumerate(vcf_reader):
            hash_fields = dict(r.INFO)
            hash_fields.update(dict(zip(r.samples[0].data._fields, r.samples[0].data)))

            # If there is genotype estimated by HipSTR we follow on, otherwise continue
            if hash_fields.get('GT') == '.':
                continue

            if vcf_input == \
                    "/Users/kibanez/Documents/STRs/ANALYSIS/population_research/HipSTR/output_HipSTR/HipSTR_output_58971_vcfs/AFR/HipSTR_LP3000874-DNA_C04.vcf":
                print("KIKI")

            # PERIOD - length of motif
            motif_length = hash_fields.get('PERIOD', '0')
            gene = str(r.ID)
            start = hash_fields.get('START')
            pos = start
            end = hash_fields.get('END') + 1
            ref_allele_size = int((end - start) / motif_length)
            alt_allele_size = str(len(str(r.ALT).split(',')[0]) / motif_length)
            if ',' in str(r.ALT):
                alt2_allele_size = str(len(str(r.ALT).split(',')[1]) / motif_length)

            gb_values = list(hash_fields.get('GB', "").split('|'))
            gb_values = list(map(int, gb_values))

            hash_variant = {}
            hash_variant['chr'] = r.CHROM
            hash_variant['gene'] = gene
            hash_variant['repeat_motif'] = str(r.REF)[0:motif_length]
            hash_variant['gt'] = str(hash_fields.get('GT', ""))
            #hash_variant['alt_size'] = str(alt_allele_size)
            #hash_variant['ref_size'] = str(ref_allele_size)
            hash_variant['num_samples'] = '1'
            hash_variant['list_samples'] = name_vcf

            # Before: each variant consists of CHROM, POS, with the REF and its ALT alleles,
            # in which alt is not the alternate allele, but the STR repeats
            # Now: depending on the genotype (GT) we will check which alleles are frequent in our cohort

            # We will call `allele` to each allele size detected in each genome
            # For loci in autosomal chromosomes, we expect to have 2 repeat sizes corresponding to both alleles
            # For loci in sexual chromosomes, we expect to have 2 repeat size alleles if the genome is female,
            # or 1 repeat size allele if the genome is male (i.e. FMR1, AR). We take the max value of both
            # alleles estimation

            if hash_variant.get('gt') == '0|0':
                allele = str(ref_allele_size)
                hash_variant['repeat-size'] = allele

                if (r.CHROM, pos, gene, allele) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele)]['num_samples'] = str(int(hash_table.get((r.CHROM, pos, gene, allele))['num_samples']) + 2)
                    hash_table[(r.CHROM, pos, gene, allele)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele))['list_samples'] + ';' + name_vcf + '_x2'
                else:
                    hash_variant['num_samples'] = '2'
                    hash_variant['list_samples'] = name_vcf + '_x2'
                    hash_table[(r.CHROM, pos, gene, allele)] = hash_variant

            elif hash_variant.get('gt') == '1|1':
                allele = str(ref_allele_size + int(gb_values[0]/motif_length))
                hash_variant['repeat-size'] = allele

                if (r.CHROM, pos, gene, allele) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele)]['num_samples'] = str(int(hash_table.get((r.CHROM, pos, gene, allele))['num_samples']) + 2)
                    hash_table[(r.CHROM, pos, gene, allele)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele))['list_samples'] + ';' + name_vcf + '_x2'
                else:
                    hash_variant['num_samples'] = '2'
                    hash_variant['list_samples'] = name_vcf + '_x2'
                    hash_table[(r.CHROM, pos, gene, allele)] = hash_variant

            # From a release we can distinguish between gender, FMR1 and AR. Only 1
            # allele if the sample is a male
            # HipSTR does not distinguish this but leaving the code anyway...
            elif hash_variant.get('gt') == '1' or hash_variant.get('gt') == '0':
                print("hemizigosis???")
                allele = alt_allele_size
                hash_variant['repeat-size'] = allele

                if (r.CHROM, pos, gene, allele) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele)]['num_samples'] = str(
                        int(hash_table.get((r.CHROM, pos, gene, allele))['num_samples']) + 1)
                    hash_table[(r.CHROM, pos, gene, allele)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele))['list_samples'] \
                        + ';' + name_vcf

                else:
                    # we add the new alternative allele info
                    hash_variant['num_samples'] = '1'
                    hash_variant['list_samples'] = name_vcf
                    hash_table[(r.CHROM, pos, gene, allele)] = hash_variant

            elif hash_variant.get('gt') == '0|1' or hash_variant.get('gt') == '1|0':
                allele_ref = str(ref_allele_size)
                allele_alt = str(int(ref_allele_size) + int(gb_values[1]/motif_length))

                if (r.CHROM, pos, gene, allele_ref) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele_ref)]['num_samples'] = str(
                        int(hash_table.get((r.CHROM, pos, gene, allele_ref))['num_samples']) + 1)
                    hash_table[(r.CHROM, pos, gene, allele_ref)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele_ref))['list_samples'] + ';' + name_vcf

                else:
                    hash_variant['repeat-size'] = allele_ref
                    hash_table[(r.CHROM, pos, gene, allele_ref)] = hash_variant

                if (r.CHROM, pos, gene, allele_alt) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele_alt)]['num_samples'] = str(
                        int(hash_table.get((r.CHROM, pos, gene, allele_alt))['num_samples']) + 1)
                    hash_table[(r.CHROM, pos, gene, allele_alt)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele_alt))['list_samples'] + ';' + name_vcf

                else:
                    hash_variant_alt = copy.deepcopy(hash_variant)
                    hash_variant_alt['repeat-size'] = allele_alt
                    hash_table[(r.CHROM, pos, gene, allele_alt)] = hash_variant_alt

            elif hash_variant.get('gt') == '1|2' or hash_variant.get('gt') == '2|1':
                allele_alt1 = str(int(ref_allele_size) + int(gb_values[0]/motif_length))
                allele_alt2 = str(int(ref_allele_size) + int(gb_values[1]/motif_length))

                if (r.CHROM, pos, gene, allele_alt1) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele_alt1)]['num_samples'] = str(
                        int(hash_table.get((r.CHROM, pos, gene, allele_alt1))['num_samples']) + 1)
                    hash_table[(r.CHROM, pos, gene, allele_alt1)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele_alt1))['list_samples'] + ';' + name_vcf
                else:
                    hash_variant['repeat-size'] = allele_alt1
                    hash_table[(r.CHROM, pos, gene, allele_alt1)] = hash_variant

                if (r.CHROM, pos, gene, allele_alt2) in hash_table:
                    hash_table[(r.CHROM, pos, gene, allele_alt2)]['num_samples'] = str(
                        int(hash_table.get((r.CHROM, pos, gene, allele_alt2))['num_samples']) + 1)
                    hash_table[(r.CHROM, pos, gene, allele_alt2)]['list_samples'] = \
                        hash_table.get((r.CHROM, pos, gene, allele_alt2))['list_samples'] + ';' + name_vcf
                else:
                    hash_variant_alt = copy.deepcopy(hash_variant)
                    hash_variant_alt['repeat-size'] = allele_alt2
                    hash_table[(r.CHROM, pos, gene, allele_alt2)] = hash_variant_alt

    for key, value in iter(hash_table.items()):
        af = float(hash_table.get(key)['num_samples']) / float(total_samples)
        hash_table[key]['AF'] = str(af)

    logger.info("Computing the allele frequencies after having digested all the individual VCF files")
    return hash_table


def read_cfg_file(cfg_filename):
    '''
    Function that reads the configuration file which includes the paths to all the fundamental input

    :param cfg_filename: configuration file
    :return: hash_table containing info in the config file
    '''
    fi = open(cfg_filename, 'r')

    config = ConfigParser.ConfigParser()
    config.readfp(fi)

    hash_cfg = {}

    for field in config.options('GENERAL'):
        hash_cfg[field] = config.get('GENERAL', field)

    for field in config.options('OUTPUT'):
        hash_cfg[field] = config.get('OUTPUT', field)

    for field in config.options('REFERENCE'):
        hash_cfg[field] = config.get('REFERENCE', field)

    for field in config.options('SOFTWARE'):
        hash_cfg[field] = config.get('SOFTWARE', field)

    fi.close()

    return hash_cfg


def run(argv=None):

    if argv is None: argv = sys.argv

    parser = OptionParser(add_help_option=True, description="")
    parser.add_option("--s", default=None,
                      help="The path in which the resulting EH VCF files are", dest="f_samples")
    parser.add_option("--o", default=None,
                      help="The output VCF name in which the merged VCF will be write",
                      dest="f_output")
    parser.add_option("--O", default=None,
                      help="The output directory in which the merged VCF will be write",
                      dest="d_output")
    (options, args) = parser.parse_args(argv[1:])

    if len(argv) == 1:
        sys.exit(0)

    if not parser.check_required("--s"):
        raise IOError('The path to the VCF files generated by running HipSTR is missing')

    if not parser.check_required("--o"):
        raise IOError('The merged VCF file is missing')

    if not parser.check_required("--O"):
        raise IOError('The output directory in which the merged VCF files will be write is missing')

    if not options.f_samples == None:

        path_samples = options.f_samples

        if not os.path.exists(path_samples):
            raise IOError('The path to the VCF files generated by running HipSTR %s does not exist') \
                  % path_samples

        # Output folder in which the output of EH will be saved
        output_folder = options.d_output

        if not os.path.exists(output_folder):
            os.mkdir(output_folder)

        merged_vcf = options.f_output

        if merged_vcf is None:
            raise IOError('The name for the merged VCF is missing %s') % merged_vcf

        output_file = os.path.join(output_folder, merged_vcf)

        # Configure logger
        formatter = logging.Formatter('%(asctime)s - %(module)s - %(levelname)s - %(message)s')
        console = logging.StreamHandler()
        console.setFormatter(formatter)
        console.setLevel(logging.INFO)
        logger = logging.getLogger("preprocess")
        logger.setLevel(logging.INFO)
        logger.addHandler(console)

        logger.info("The process of merging all the individual VCF files has started")

        # Here we retrieve all the VCF files generated by running EH algorithm in a cohort
        # EH for each sample generates a *.json, *.vcf and *.log file
        # we are interested in the VCF files

        l_vcf = [f for f in os.listdir(path_samples) if f.endswith('.vcf')]

        l_samples = []

        for vcf in l_vcf:
            sample_name = re.sub('^HipSTR_', '', vcf)
            sample_name = re.sub('.vcf$', '', sample_name)
            l_samples.append(sample_name)

        hash_table = merging_vcf(l_vcf, path_samples, logger)

        print_tables(hash_table, output_file)

        logger.info('The merged VCF files has been annotated and enriched - %s' % output_file)


if __name__ == '__main__':
    run()